/** 
\page build_instruct GPU Graph Library Build Instruction
\brief Build instruction for GPU graph library

This document provides instructions for compiling and using the GPU graph library on
Linux environments.

\section intro Introduction
The library is based on Duane Merrill's GPU Breadth First Search(BFS) code and uses his
<a href="https://code.google.com/p/back40computing">back40computing library</a>. The
graph-related code is located in gpugraph/b40c/graph, and the test code is located in
gpugraph/test/bfs and gpugraph/test/cc.

\section prereq Prerequisites
\li <a href="https://developer.nvidia.com/cuda-downloads">CUDA</a> The code is tested
under CUDA 4.1 and CUDA 5.0. Generally for better performance, CUDA 5.0+ is preferred.

\section build_bfs Build Breadth-First Search Test Code
The GPU Graph Library is a template-based library and thus only need to include
according header files to use it in your project. A user can go through the following
steps to build the test code that uses library. Test code shows how to integrate
GPU graph library to your project.

  \li Before you build the test code, make sure CUDA is properly installed.
      You can test this by typing: "which nvcc". If properly installed and
      the path has been added to PATH, the command will tell you where
      NVIDIA CUDA Compiler is located on your machine. If your machine is
      not 64-bit, you need to open gpugraph/test/bfs/Makefile, comment
      out the 26th line: "force64 = 1".

  \li Now we can build test_bfs program by simply typing "make" under
      gpugraph/test/bfs.

  \li If the build succeeded, you can find the generated executable file
      under gpugraph/test/bfs/bin. The name of the executable file implies
      the CUDA version and your machine architecture.

\section build_cc Build Connected Component Labeling Test Code
  
  \li Before you build the test code, make sure CUDA is properly installed.
      You can test this by typing: "which nvcc". If properly installed and
      the path has been added to PATH, the command will tell you where
      NVIDIA CUDA Compiler is located on your machine. If your machine is
      not 64-bit, you need to open gpugraph/test/cc/Makefile, comment out
      the 5th line: "force64 = 1".

  \li Build test_cc program by simply typing "make" under gpugraph/test/cc.

  \li If the build succeeded, you can find the generated executable file
      under gpugraph/test/cc/bin. The name of the executable file implies
      the CUDA version and your machine architecture.

\section dataset Dataset Preparation
The current BFS code uses Compressed Sparse Row (CSR) to present graph and
supports several types of graph data format including: DIMACS, Matrix Market,
METIS, R-Mat, Grid2D, Grid3D, Random Data, and Charity Net Data.
For CharityNet Dataset, the only tested one can be acquired from XDATA VPN site:
\code
http://xd-fileshare.xdata.data-tactics-corp.com/FileShare/InitialData/CharityNet/charity_net_clean_2oct2012.zip
\endcode
After you get the zip file, unzip it and place the following file under gpugraph/dataset:
\code
charity_net_transaction.txt
\endcode
There is a simple python script under the same direcotry. To parse the transaction records, use
\code
python readfile.py charity_net_transaction.txt
\endcode
Note that this operation is in place, so it will ruin the original file.

For other graph types, see the Usage of test_bfs program below.

The current Connected Component Labeling code take a Matrix Market format graph file with
node_number and edge_number in the first line and edge tuple information in the following
lines. Three test graphs can be found using the following link:
\code
http://snap.stanford.edu/data/cit-Patents.txt.gz
http://snap.stanford.edu/data/roadNet-CA.txt.gz
http://snap.stanford.edu/data/wiki-Talk.txt.gz
\endcode

Before data can be used for the algorithm, one should perform the following preprocessig
steps:

1) Download and unzip the graph file.

2) Extract node number and edge number from the first few comment lines of the file and
delete all the comment lines, leave only one line with two integers, the first represents
node number and the second represents edge number. For example, if the first few lines of
the file looks like:
\code
# Directed graph (each unordered pair of nodes is saved once): roadNet-CA.txt 
# California road network
# Nodes: 1965206 Edges: 5533214
# FromNodeId  ToNodeId
\endcode
After preprocessing, it should look like:
\code
1965206 5533214
\endcode

3) There is a simple python script under gpugraph/dataset. Parse the graph file one has
operated in step 2 using:
\code
python gengraph.py graph_file
\endcode
Note that this operation is in place, so it will ruin the original file.

\section run Run BFS Test Program
To get help of how to run the BFS test program, just type:
./test_bfs with no parameters, you will see the usage instruction below:

\code
test_bfs <graph type> <graph type args> [--device=<device index>] [--v] [--instrumented] [--i=<num-iterations>] [--undirected][--src=< <source idx> | randomize >] [--queue-sizing=<sizing factor>
[--mark-pred] [--strategy=<strategy>[,<strategy>]*]

Unless otherwise specified, all graph types use 4-byte vertex-identifiers.

Graph types and args:
  grid2d <width>
    2D square grid lattice having width <width>.  Interior vertices 
    have 4 neighbors and 1 self-loop.  Default source vertex is the grid-center.
  grid3d <side-length>
    3D square grid lattice having width <width>.  Interior vertices 
    have 6 neighbors and 1 self-loop.  Default source vertex is the grid-center.
  dimacs [<file>]
    Reads a DIMACS-formatted graph of directed edges from stdin (or 
    from the optionally-specified file).  Default source vertex is random.
  metis [<file>]
    Reads a METIS-formatted graph of directed edges from stdin (or 
    from the optionally-specified file).  Default source vertex is random.
  market [<file>]
    Reads a Matrix-Market coordinate-formatted graph of directed edges from stdin (or 
    from the optionally-specified file).  Default source vertex is random.
  random <n> <m>
    A random graph generator that adds <m> edges to <n> nodes by randomly 
    choosing a pair of nodes for each edge.  There are possibilities of 
    loops and multiple edges between pairs of nodes. Default source vertex 
    is random.
  rr <n> <d>
    A random graph generator that adds <d> randomly-chosen edges to each
    of <n> nodes.  There are possibilities of loops and multiple edges
    between pairs of nodes. Default source vertex is random.
  g500 <n>
    An R-MAT graph generator that adds 16n undirected edges to <n> nodes in accordance with
    the Graph500 problem specification (8-byte vertex identifiers, A=.57,B=.19,C=.19,D=.05     skew parameters).
  rmat <n> <m>
    An R-MAT graph generator that adds <m> edges to <n> nodes in accordance with
    the GTGraph generator defaults (A=.45,B=.15,C=.15,D=.25 skew parameters
  charitynet <file>
    Reads a directed graph CharityNet data from file. Default source vertex is random.

--strategy  Specifies the strategies to evaluate when num-gpus specified <= 1.
  Valid strategies are: {0, 1, 2, 3}. Default: 3
      "0": expand-contract
        - Two O(n) global ping-pong buffers (out-of-core vertex frontier)
        - single kernel invocation (in-kernel software global barriers between BFS iterations)
        - Predecessor-marking not implemented
      "1": contract-expand
        - Two O(m) global ping-pong buffers (out-of-core edge frontier)
        - Single kernel invocation (in-kernel software global barriers between BFS iterations)
      "2": two-phase
        - Uneven O(n) and O(m) global ping-pong buffers (out-of-core vertex and edge frontiers)
        - Two kernel invocations per BFS iteration (pipelined)
      "3": hybrid of contract-expand and two-phase strategies
        - Uses high-throughput two-phase for BFS iterations with lots of concurrency,
          switching to contract-expand when frontier falls below a certain threshold
        - Two O(m) global ping-pong buffers 

--v  Verbose launch and statistical output is displayed to the console.

--v2  Same as --v, but also displays the input graph to the console.

--instrumented  Kernels keep track of queue-search_depth, redundant work (i.e., the 
    overhead of duplicates in the frontier), and average barrier duty (a 
    relative indicator of load imbalance.)

--i  Performs <num-iterations> test-iterations of BFS traversals.
    Default = 1

--src  Begins BFS from the vertex <source idx>. Default is specific to 
    graph-type.  If alternatively specified as "randomize", each 
    test-iteration will begin with a newly-chosen random source vertex.

--queue-sizing  Allocates a frontier queue sized at (graph-edges * <queue-sizing>).  Default
    is 1.15.

--mark-pred  Parent vertices are marked instead of source distances, i.e., it
    creates an ancestor tree rooted at the source vertex.

--with-value Will perform a simple computation which sums all the edge values to neighbors
    and stores it as the node value

--stream-from-host  Keeps the graph data (column indices, row offsets) on the host,
    using zero-copy access to traverse it.

--num-gpus  Number of GPUs to use

--undirected  Edges are undirected.  Reverse edges are added to DIMACS and
    random graphs, effectively doubling the CSR graph representation size.
    Grid2d/grid3d graphs are undirected regardless of this flag, and rr 
    graphs are directed regardless of this flag.
\endcode

Here are two examples of how to run test_bfs (suppose the program runs on an 64-bit machine which
has CUDA 5.0 installed):

1) Run test_bfs on charity net dataset with node value computation for 1000 iterations, with CPU
reference running off, and verbose information display on. Specify the source node as the node with
VertexId 177. Pipe the result to a separate file:
\code
./test_bfs_5.0_x86_64 charitynet graph_data_path/graph_data_file --src=177 --i=1000 --quick --with-value --v2 > result
\endcode

2) Run test_bfs on a random graph with 200 nodes and 2000 edges with 1 iteration, the source node as randomize,
with CPU reference running off, and verbose information display on. Pipe the result to a separate file:
\code
./test_bfs_5.0_x86_64 random 200 2000 --i=1 --src=randomize --quick --v2 > result
\endcode

\section run_cc Run Connected Component Labeling Test Program
To get help of how to run the CC test program, just type:
./test_cc with no parameters, you will see the usage instruction below:

\code
test_cc <graph_type> <graph_type_args> [--device=<device_index>]  [--v] [--instrumented] [--i=<num-iterations>]
All graph types use 8-byte vertex-identifiers.

Graph types and args:
  fromfile <filename>
    Reads an undirected graph from file.

--v Verbose launch and statistical output is displayed to the console.

--instrumented Kernels keep track of iteration and average barrier duty.

--i Performs <num-iterations> test-iterations of CC algorithms.
     Default = 1
--gpu_index Index of device intend to use.
\endcode

Here are the example of how to run test_cc (suppose the program runs on an 64-bit machine which has CUDA 5.0 installed):

1) Run test_cc on California road network graph. Pipe the result to a separate file:
\code
./test_cc_5.0_x86_64 fromfile roadNet-CA.graph > result
\endcode

**/
